{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import types\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#PyTorch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Importing our custom module(s)\n",
    "import layers\n",
    "import likelihoods\n",
    "import losses\n",
    "import metrics\n",
    "import priors\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    'python ../src/encode_cifar10.py --batch_size=128 --cifar10_dir=\"/cluster/tufts/hugheslab/eharve06/CIFAR-10\" --cifar101_v4_dir=\"/cluster/tufts/hugheslab/eharve06/CIFAR-10.1\" --encoded_path=\"/cluster/tufts/hugheslab/eharve06/random-Fourier-features/datasets/CIFAR-10/n=100_random_state=1001.pth\" --n=100 --num_workers=0 --random_state=1001'\n",
      "    'python ../src/encode_cifar10.py --batch_size=128 --cifar10_dir=\"/cluster/tufts/hugheslab/eharve06/CIFAR-10\" --cifar101_v4_dir=\"/cluster/tufts/hugheslab/eharve06/CIFAR-10.1\" --encoded_path=\"/cluster/tufts/hugheslab/eharve06/random-Fourier-features/datasets/CIFAR-10/n=100_random_state=2001.pth\" --n=100 --num_workers=0 --random_state=2001'\n",
      "    'python ../src/encode_cifar10.py --batch_size=128 --cifar10_dir=\"/cluster/tufts/hugheslab/eharve06/CIFAR-10\" --cifar101_v4_dir=\"/cluster/tufts/hugheslab/eharve06/CIFAR-10.1\" --encoded_path=\"/cluster/tufts/hugheslab/eharve06/random-Fourier-features/datasets/CIFAR-10/n=100_random_state=3001.pth\" --n=100 --num_workers=0 --random_state=3001'\n",
      "    'python ../src/encode_cifar10.py --batch_size=128 --cifar10_dir=\"/cluster/tufts/hugheslab/eharve06/CIFAR-10\" --cifar101_v4_dir=\"/cluster/tufts/hugheslab/eharve06/CIFAR-10.1\" --encoded_path=\"/cluster/tufts/hugheslab/eharve06/random-Fourier-features/datasets/CIFAR-10/n=1000_random_state=1001.pth\" --n=1000 --num_workers=0 --random_state=1001'\n",
      "    'python ../src/encode_cifar10.py --batch_size=128 --cifar10_dir=\"/cluster/tufts/hugheslab/eharve06/CIFAR-10\" --cifar101_v4_dir=\"/cluster/tufts/hugheslab/eharve06/CIFAR-10.1\" --encoded_path=\"/cluster/tufts/hugheslab/eharve06/random-Fourier-features/datasets/CIFAR-10/n=1000_random_state=2001.pth\" --n=1000 --num_workers=0 --random_state=2001'\n",
      "    'python ../src/encode_cifar10.py --batch_size=128 --cifar10_dir=\"/cluster/tufts/hugheslab/eharve06/CIFAR-10\" --cifar101_v4_dir=\"/cluster/tufts/hugheslab/eharve06/CIFAR-10.1\" --encoded_path=\"/cluster/tufts/hugheslab/eharve06/random-Fourier-features/datasets/CIFAR-10/n=1000_random_state=3001.pth\" --n=1000 --num_workers=0 --random_state=3001'\n",
      "    'python ../src/encode_cifar10.py --batch_size=128 --cifar10_dir=\"/cluster/tufts/hugheslab/eharve06/CIFAR-10\" --cifar101_v4_dir=\"/cluster/tufts/hugheslab/eharve06/CIFAR-10.1\" --encoded_path=\"/cluster/tufts/hugheslab/eharve06/random-Fourier-features/datasets/CIFAR-10/n=10000_random_state=1001.pth\" --n=10000 --num_workers=0 --random_state=1001'\n",
      "    'python ../src/encode_cifar10.py --batch_size=128 --cifar10_dir=\"/cluster/tufts/hugheslab/eharve06/CIFAR-10\" --cifar101_v4_dir=\"/cluster/tufts/hugheslab/eharve06/CIFAR-10.1\" --encoded_path=\"/cluster/tufts/hugheslab/eharve06/random-Fourier-features/datasets/CIFAR-10/n=10000_random_state=2001.pth\" --n=10000 --num_workers=0 --random_state=2001'\n",
      "    'python ../src/encode_cifar10.py --batch_size=128 --cifar10_dir=\"/cluster/tufts/hugheslab/eharve06/CIFAR-10\" --cifar101_v4_dir=\"/cluster/tufts/hugheslab/eharve06/CIFAR-10.1\" --encoded_path=\"/cluster/tufts/hugheslab/eharve06/random-Fourier-features/datasets/CIFAR-10/n=10000_random_state=3001.pth\" --n=10000 --num_workers=0 --random_state=3001'\n",
      "    'python ../src/encode_cifar10.py --batch_size=128 --cifar10_dir=\"/cluster/tufts/hugheslab/eharve06/CIFAR-10\" --cifar101_v4_dir=\"/cluster/tufts/hugheslab/eharve06/CIFAR-10.1\" --encoded_path=\"/cluster/tufts/hugheslab/eharve06/random-Fourier-features/datasets/CIFAR-10/n=50000_random_state=1001.pth\" --n=50000 --num_workers=0 --random_state=1001'\n",
      "    'python ../src/encode_cifar10.py --batch_size=128 --cifar10_dir=\"/cluster/tufts/hugheslab/eharve06/CIFAR-10\" --cifar101_v4_dir=\"/cluster/tufts/hugheslab/eharve06/CIFAR-10.1\" --encoded_path=\"/cluster/tufts/hugheslab/eharve06/random-Fourier-features/datasets/CIFAR-10/n=50000_random_state=2001.pth\" --n=50000 --num_workers=0 --random_state=2001'\n",
      "    'python ../src/encode_cifar10.py --batch_size=128 --cifar10_dir=\"/cluster/tufts/hugheslab/eharve06/CIFAR-10\" --cifar101_v4_dir=\"/cluster/tufts/hugheslab/eharve06/CIFAR-10.1\" --encoded_path=\"/cluster/tufts/hugheslab/eharve06/random-Fourier-features/datasets/CIFAR-10/n=50000_random_state=3001.pth\" --n=50000 --num_workers=0 --random_state=3001'\n"
     ]
    }
   ],
   "source": [
    "cifar10_dir = \"/cluster/tufts/hugheslab/eharve06/CIFAR-10\"\n",
    "cifar101_v4_dir = \"/cluster/tufts/hugheslab/eharve06/CIFAR-10.1\"\n",
    "ns = [100, 1_000, 10_000, 50_000]\n",
    "random_states = [1001, 2001, 3001]\n",
    "repo_dir = \"/cluster/tufts/hugheslab/eharve06/random-Fourier-features\"\n",
    "\n",
    "for n, random_state in itertools.product(ns, random_states):\n",
    "    encoded_path = f\"{repo_dir}/datasets/CIFAR-10/n={n}_random_state={random_state}.pth\"\n",
    "    print(\n",
    "        f\"    \\'python ../src/encode_cifar10.py \"\n",
    "        f\"--batch_size=128 \"\n",
    "        f\"--cifar10_dir=\\\"{cifar10_dir}\\\" \"\n",
    "        f\"--cifar101_v4_dir=\\\"{cifar101_v4_dir}\\\" \"\n",
    "        f\"--encoded_path=\\\"{encoded_path}\\\" \"\n",
    "        f\"--n={n} \"\n",
    "        f\"--num_workers=0 \"\n",
    "        f\"--random_state={random_state}\\'\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7500)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = torch.tensor([[3.0, -1.0], [-1.0, 2.0], [0.0, 1.0], [-1.0, 3.0]])\n",
    "probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "preds = torch.argmax(probs, dim=1)\n",
    "labels = torch.tensor([0, 0, 1, 1]).long()\n",
    "metrics.balanced_accuracy(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.abstention_metric(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, random_state = 100, 1001\n",
    "datasets = torch.load(f\"{repo_dir}/datasets/CIFAR-10/n={n}_random_state={random_state}.pth\", map_location=torch.device(\"cpu\"), weights_only=False)\n",
    "\n",
    "full_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.cat([datasets[\"X_train\"], datasets[\"X_val\"]], dim=0),\n",
    "    torch.cat([datasets[\"y_train\"], datasets[\"y_val\"]], dim=0),\n",
    ")\n",
    "train_dataset = torch.utils.data.TensorDataset(datasets[\"X_train\"], datasets[\"y_train\"])\n",
    "val_dataset = torch.utils.data.TensorDataset(datasets[\"X_val\"], datasets[\"y_val\"])\n",
    "test_dataset = torch.utils.data.TensorDataset(datasets[\"X_test\"], datasets[\"y_test\"])\n",
    "ood_dataset = torch.utils.data.TensorDataset(datasets[\"X_ood\"], datasets[\"y_ood\"])\n",
    "\n",
    "batch_size = 128\n",
    "full_dataloader = torch.utils.data.DataLoader(full_dataset, batch_size=batch_size)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
    "ood_dataloader = torch.utils.data.DataLoader(ood_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, criterion, optimizer, dataloader, num_samples=1):\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    dataset_size = len(dataloader) * dataloader.batch_size if dataloader.drop_last else len(dataloader.dataset)\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        \n",
    "        batch_size = len(X_batch)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        params = utils.flatten_params(model)\n",
    "        \n",
    "        for _ in range(num_samples):\n",
    "            logits = model(X_batch)\n",
    "            loss = criterion(logits, y_batch, params, len(dataloader.dataset))\n",
    "            total_loss += (batch_size / dataset_size) * (1 / num_samples) * loss.item()\n",
    "            loss.backward()\n",
    "            \n",
    "        for group in optimizer.param_groups:\n",
    "            for param in group[\"params\"]:\n",
    "                if param.grad is not None:\n",
    "                    param.grad.data.mul_(1/num_samples)\n",
    "\n",
    "        for group in optimizer.param_groups:\n",
    "            torch.nn.utils.clip_grad_norm_(group[\"params\"], max_norm=1.0)\n",
    "            \n",
    "        optimizer.step()\n",
    "        \n",
    "    return total_loss\n",
    "        \n",
    "def evaluate(model, criterion, dataloader):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    dataset_size = len(dataloader) * dataloader.batch_size if dataloader.drop_last else len(dataloader.dataset)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        for X_batch, y_batch in dataloader:\n",
    "\n",
    "            batch_size = len(X_batch)\n",
    "            \n",
    "            params = utils.flatten_params(model)\n",
    "            logits = model(X_batch)\n",
    "            loss = criterion(logits, y_batch, params, len(dataloader.dataset))\n",
    "            total_loss += (batch_size / dataset_size) * loss.item()\n",
    "            \n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:03<00:00, 158.20it/s]\n",
      "100%|██████████| 10000/10000 [01:07<00:00, 148.05it/s]\n",
      "100%|██████████| 10000/10000 [01:12<00:00, 137.92it/s]\n",
      "100%|██████████| 10000/10000 [01:15<00:00, 132.77it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = layers.RFFLaplace(in_features=2048, out_features=10, rank=1024, lengthscale=20.0, outputscale=1.0)\n",
    "likelihood = likelihoods.CategoricalLikelihood()\n",
    "prior = priors.GaussianPrior(learnable_tau=False, tau=1.0)\n",
    "\n",
    "map_objective = losses.MAPLoss(likelihood, prior)\n",
    "cross_entropy = losses.ERMLoss(likelihood)\n",
    "\n",
    "state_dict = {\n",
    "    \"model\": model.state_dict(),\n",
    "    \"likelihood\": likelihood.state_dict(),\n",
    "    \"prior\": prior.state_dict(),\n",
    "}\n",
    "\n",
    "columns = [\"lr\", \"epoch\", \"train_loss\", \"val_loss\"]\n",
    "model_history_df = pd.DataFrame(columns=columns)\n",
    "best_state_dict = None\n",
    "\n",
    "for lr in [0.1, 0.01, 0.001, 0.0001]:\n",
    "\n",
    "    model.load_state_dict(state_dict[\"model\"])\n",
    "    likelihood.load_state_dict(state_dict[\"likelihood\"])\n",
    "    prior.load_state_dict(state_dict[\"prior\"])\n",
    "    \n",
    "    optimizer = torch.optim.Adam([{\"params\": model.parameters()}, {\"params\": likelihood.parameters()}, {\"params\": prior.parameters()}], lr=lr, weight_decay=0.0)\n",
    "    \n",
    "    epochs = 10_000\n",
    "    \n",
    "    for epoch in tqdm.tqdm(range(epochs)):\n",
    "        \n",
    "        train_loss = train_one_epoch(model, map_objective, optimizer, train_dataloader)\n",
    "        val_loss = evaluate(model, cross_entropy, val_dataloader)\n",
    "        \n",
    "        model_history_df.loc[len(model_history_df)] = [lr, epoch, train_loss, val_loss]\n",
    "        \n",
    "        if val_loss == model_history_df[\"val_loss\"].min(): \n",
    "            best_state_dict = {\n",
    "                \"model\": model.state_dict(),\n",
    "                \"likelihood\": likelihood.state_dict(),\n",
    "                \"prior\": prior.state_dict(),\n",
    "            }\n",
    "        \n",
    "model.load_state_dict(best_state_dict[\"model\"])\n",
    "likelihood.load_state_dict(best_state_dict[\"likelihood\"])\n",
    "prior.load_state_dict(best_state_dict[\"prior\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_lr = model_history_df.lr[model_history_df.val_loss.idxmin()]\n",
    "temp_df = model_history_df[model_history_df.lr == best_lr]\n",
    "\n",
    "print(best_lr)\n",
    "\n",
    "ncols, nrows = 1, 1\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4*ncols, 3*nrows), ncols=ncols, nrows=nrows)\n",
    "\n",
    "ax.plot(temp_df.epoch, temp_df.train_loss, label=\"Train\")\n",
    "ax.plot(temp_df.epoch, temp_df.val_loss, label=\"Val\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6955999135971069\n",
      "0.5629934072494507\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    model.update_covariance_from_dataloader(train_dataloader)\n",
    "\n",
    "    test_probs = model.predict_proba(datasets[\"X_test\"], num_samples=10_000)\n",
    "    ood_probs = model.predict_proba(datasets[\"X_ood\"], num_samples=10_000)\n",
    "        \n",
    "    test_preds = torch.argmax(test_probs, dim=1)\n",
    "    ood_preds = torch.argmax(ood_probs, dim=1)\n",
    "\n",
    "    test_acc = metrics.balanced_accuracy(test_preds, datasets[\"y_test\"])\n",
    "    ood_acc = metrics.balanced_accuracy(ood_preds, datasets[\"y_ood\"])\n",
    "    \n",
    "    print(test_acc.item())\n",
    "    print(ood_acc.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "l3d_2024f_cuda12_1",
   "language": "python",
   "name": "l3d_2024f_cuda12_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
